{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining focal length\n",
    "The focal length ð‘“ can be determined experimentally by following these steps:\n",
    "\n",
    "Object Measurement:\n",
    "\n",
    "Select an object of known size. For example, take a ruler or box with a known width ð‘Š (in real units like centimeters).\n",
    "Place this object at a known distance ð· from the camera (for example, 100 cm).\n",
    "\n",
    "Shooting an image:\n",
    "\n",
    "Take an image of this object using your camera.\n",
    "Picture Measurement:\n",
    "\n",
    "Measure the width of the object in the image in pixels ð‘ƒ.\n",
    "Calculation of focal length:\n",
    "\n",
    "Use the formula to calculate the focal length:\n",
    "\n",
    "\n",
    "ð‘“ = (ð‘ƒ â‹…ð·) / ð‘Š\n",
    " \n",
    "Example\n",
    "Let's say you select an object that is 20 cm wide and place it 100 cm away from the camera. In the image, the width of the object is 200 pixels. Then the focal length can be calculated as follows:\n",
    "\n",
    "ð‘“ = (200pixels â‹… 100cm) / 20cm = 1000pixels\n",
    "\n",
    "Using Focal Length\n",
    "Once you have determined the focal length, you can use it to calculate the distance to any object of known size in the image. In your case, you can use the following formula to calculate the distance to a person:\n",
    "\n",
    "ð· = (ð‘Š â‹…ð‘“) / ð‘ƒ\n",
    "Where:\n",
    "\n",
    "ð· - distance to object\n",
    "ð‘Š - real width of the object (person) in centimeters\n",
    "ð‘“ - focal length in pixels\n",
    "ð‘ƒ - width of the object in the image in pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxkucher/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 2 cars, 1 traffic light, 373.7ms\n",
      "Speed: 3.8ms preprocess, 373.7ms inference, 590.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 443.4ms\n",
      "Speed: 1.9ms preprocess, 443.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 350.0ms\n",
      "Speed: 22.4ms preprocess, 350.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 343.7ms\n",
      "Speed: 1.4ms preprocess, 343.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 343.1ms\n",
      "Speed: 2.1ms preprocess, 343.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 345.9ms\n",
      "Speed: 1.9ms preprocess, 345.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 342.9ms\n",
      "Speed: 6.2ms preprocess, 342.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 335.9ms\n",
      "Speed: 1.6ms preprocess, 335.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 355.6ms\n",
      "Speed: 4.1ms preprocess, 355.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 323.3ms\n",
      "Speed: 1.6ms preprocess, 323.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 326.2ms\n",
      "Speed: 1.6ms preprocess, 326.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# main videofile \n",
    "cap = cv2.VideoCapture(\"/Users/maxkucher/data_handling/yolo_destination/road_3.mp4\")\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# # we are going to define focus destination based on 'car' object from this video\n",
    "cap_temp = cv2.VideoCapture(\"/Users/maxkucher/data_handling/yolo_destination/road_2.mp4\")\n",
    "t_ret, t_frame = cap_temp.read()\n",
    "\n",
    "model = YOLO(\"yolov8l\")\n",
    "\n",
    "names = model.names\n",
    "threshold = 0.5\n",
    "\n",
    "# real width of objects (for road_2)\n",
    "real_width_car = 400\n",
    "real_width_person = 50\n",
    "\n",
    "\n",
    "# known distance between camera and 'car' for cap_temp\n",
    "known_distance = 450\n",
    "\n",
    "# define f based on 'auto'\n",
    "pre_results =  model(t_frame)[0]\n",
    "\n",
    "focal_length = None\n",
    "\n",
    "for result in pre_results.boxes.data.tolist():\n",
    "    x1, _, x2, _, score, class_id = result\n",
    "    name = names[int(class_id)]\n",
    "    if score > threshold and name == \"car\":\n",
    "        # define width in pixels of \"car\"\n",
    "        width_in_pixels = x2 - x1\n",
    "        # f = P * D / W\n",
    "        focal_length = (width_in_pixels * known_distance) / real_width_car\n",
    "        break\n",
    "\n",
    "if focal_length is None:\n",
    "    print(\"Focus destination is not detected.\")\n",
    "    exit()\n",
    "\n",
    "# run main video with defined destination \n",
    "while ret:\n",
    "\n",
    "    results = model(frame)[0]\n",
    "\n",
    "    for result in results.boxes.data.tolist():\n",
    "          obj_list = [\"car\", \"person\"]\n",
    "          x1, y1, x2, y2, score, class_id = result\n",
    "          name = names[int(class_id)]\n",
    "          if score > threshold and name in obj_list:\n",
    "                \n",
    "            \n",
    "            width_in_pixels = x2 - x1\n",
    "\n",
    "            if name == \"car\":\n",
    "                  real_width = real_width_car\n",
    "            elif name == \"person\":\n",
    "                  real_width = real_width_person\n",
    "            \n",
    "            # D = (W * f) / P - and turn to meters \n",
    "            distance = ((real_width * focal_length) / width_in_pixels) // 100\n",
    "\n",
    "\n",
    "\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            text = f\"{name}: {distance:.2f} m\"\n",
    "            cv2.putText(frame, text, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "    ret, frame = cap.read()\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
